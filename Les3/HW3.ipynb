{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание #3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zhwkeWtb1O0w"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FeKFn2yb1To4"
   },
   "outputs": [],
   "source": [
    "X = np.array([ [   1,    1,  500,    1],\n",
    "               [   1,    1,  700,    1],\n",
    "               [   1,    2,  750,    2],\n",
    "               [   1,    5,  600,    1],\n",
    "               [   1,    3, 1450,    2],\n",
    "               [   1,    0,  800,    1],\n",
    "               [   1,    5, 1500,    3],\n",
    "               [   1,   10, 2000,    3],\n",
    "               [   1,    1,  450,    1],\n",
    "               [   1,    2, 1000,    2]], dtype=np.float64)\n",
    "\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-aO1NTxOUfo"
   },
   "outputs": [],
   "source": [
    "def standard_scale(x):\n",
    "    res = (x - x.mean()) / x.std()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D8EL0iGJOVpe"
   },
   "outputs": [],
   "source": [
    "X_st = X.copy()\n",
    "X_st[:, 2] = standard_scale(X[:, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. *Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Добавим к обоим вероятностям очень малую величину, чтобы значения никогда не становились ровным нулём*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMR5pOA38dDw"
   },
   "outputs": [],
   "source": [
    "def calc_logloss(y, y_pred):\n",
    "    err = - np.mean(y * np.log(y_pred + 1e-100) + (1.0 - y) * np.log(1.0 - y_pred+ 1e-100))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R6zfOHMrBvnX",
    "outputId": "46df0625-963f-4401-da30-b5b42bcf1be7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05268025782891314"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Работает с 1 для первого класса\n",
    "y1 = np.array([1, 0])\n",
    "y_pred1 = np.array([1, 0.1])\n",
    "calc_logloss(y1, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230.25850929940458"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# И с 0 тоже\n",
    "y1 = np.array([1, 0])\n",
    "y_pred1 = np.array([0, 1])\n",
    "calc_logloss(y1, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EEF9rWPNDnss"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtgUN3LW-UIq"
   },
   "outputs": [],
   "source": [
    "def eval_model(X, y, iterations, eta=1e-4):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        z = np.dot(X, W)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        \n",
    "        dQ = 1/n * X.T @ (y_pred - y)\n",
    "        W -= eta * dQ\n",
    "#         if i % (iterations / 10) == 0:\n",
    "#             print(i, W, err)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best num of iterations: 1500\n",
      "Best eta: 10\n",
      "Error: 0.06923477957405143\n"
     ]
    }
   ],
   "source": [
    "iters = [100,300,500,750,1000,1250,1500]\n",
    "etas = [1e-5, 1e-4, 1e-2, 1e-1, 1, 5,10]\n",
    "best_err = np.inf\n",
    "best_iter = 0\n",
    "best_eta = 0\n",
    "for eta in etas:\n",
    "    for iterations in iters:\n",
    "        err = eval_model(X_st, y, iterations, eta)\n",
    "        if err < best_err:\n",
    "            best_err = err\n",
    "            best_eta = eta\n",
    "            best_iter = iterations\n",
    "print(f'Best num of iterations: {best_iter}\\nBest eta: {best_eta}\\nError: {best_err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best num of iterations: 4000\n",
      "Best eta: 20\n",
      "Error: 0.02002406286431499\n"
     ]
    }
   ],
   "source": [
    "iters = range(2000,4001,250)\n",
    "etas = range(10,21)\n",
    "best_err = np.inf\n",
    "best_iter = 0\n",
    "best_eta = 0\n",
    "for eta in etas:\n",
    "    for iterations in iters:\n",
    "        err = eval_model(X_st, y, iterations, eta)\n",
    "        if err < best_err:\n",
    "            best_err = err\n",
    "            best_eta = eta\n",
    "            best_iter = iterations\n",
    "print(f'Best num of iterations: {best_iter}\\nBest eta: {best_eta}\\nError: {best_err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best num of iterations: 6000\n",
      "Best eta: 30\n",
      "Error: 0.0069230512005412585\n"
     ]
    }
   ],
   "source": [
    "iters = range(4000,6001,250)\n",
    "etas = range(19,31)\n",
    "best_err = np.inf\n",
    "best_iter = 0\n",
    "best_eta = 0\n",
    "for eta in etas:\n",
    "    for iterations in iters:\n",
    "        err = eval_model(X_st, y, iterations, eta)\n",
    "        if err < best_err:\n",
    "            best_err = err\n",
    "            best_eta = eta\n",
    "            best_iter = iterations\n",
    "print(f'Best num of iterations: {best_iter}\\nBest eta: {best_eta}\\nError: {best_err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best num of iterations: 10000\n",
      "Best eta: 40\n",
      "Error: 0.0031318046681487444\n"
     ]
    }
   ],
   "source": [
    "iters = range(6000,10001,500)\n",
    "etas = range(30,41)\n",
    "best_err = np.inf\n",
    "best_iter = 0\n",
    "best_eta = 0\n",
    "for eta in etas:\n",
    "    for iterations in iters:\n",
    "        err = eval_model(X_st, y, iterations, eta)\n",
    "        if err < best_err:\n",
    "            best_err = err\n",
    "            best_eta = eta\n",
    "            best_iter = iterations\n",
    "print(f'Best num of iterations: {best_iter}\\nBest eta: {best_eta}\\nError: {best_err}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Нет предела совершенству. Модель пытается сделать веса как можно больше и стать как можно более определённой - попахивает переобучением**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(X, y, iterations, eta=1e-4):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        z = np.dot(X, W)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        \n",
    "        dQ = 1/n * X.T @ (y_pred - y)\n",
    "        W -= eta * dQ\n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(i, W, err)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(X, W):\n",
    "    z = np.dot(X, W)\n",
    "    y_pred_proba = sigmoid(z)\n",
    "    \n",
    "    return y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.11732727 -1.58914029  0.62030812  0.95688359] 1.1785958344356262\n",
      "50 [-1.48365228 -1.16894488  0.99986115  2.70236578] 0.4207160938550957\n",
      "100 [-2.68396104 -1.09850921  0.41147346  3.3035063 ] 0.376688731677525\n",
      "150 [-3.63451714 -1.02252273 -0.00433557  3.85591005] 0.34439983170322713\n",
      "200 [-4.41287339 -0.99229753 -0.31788504  4.35903595] 0.32381097929290387\n",
      "250 [-5.08049306 -1.01119694 -0.56675436  4.81351652] 0.30943284881700894\n",
      "300 [-5.66768311 -1.03695294 -0.77564504  5.22827197] 0.29816119935223695\n",
      "350 [-6.19452831 -1.06383826 -0.95806695  5.61000065] 0.28898264695974835\n",
      "400 [-6.67496025 -1.09092338 -1.12113672  5.96483423] 0.281278786136455\n",
      "450 [-7.11882917 -1.11785513 -1.26938355  6.29768619] 0.27465193692192175\n"
     ]
    }
   ],
   "source": [
    "W = eval_model(X_st, y, iterations=500, eta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33440702, 0.21974893, 0.98288316, 0.00385891, 0.70695586,\n",
       "       0.39829118, 0.99365837, 0.10788832, 0.36734662, 0.96534066])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred =calc_pred_proba(X_st, W)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(X, W):\n",
    "    z = np.dot(X, W)\n",
    "    y_pred = sigmoid(z)\n",
    "    y_pred = np.array([1 if i >= 0.5 else 0 for i in y_pred])\n",
    "    return (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred =calc_pred(X_st, W)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. *Реализуйте функции для подсчета Accuracy, матрицы ошибок, точности и полноты, а также F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y, y_pred, beta=1):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == y_pred[i] == 1:\n",
    "            tp +=1\n",
    "        elif y[i] == y_pred[i] == 0:\n",
    "            tn +=1\n",
    "        elif y[i] == 1 and y_pred[i] == 0:\n",
    "            fn += 1\n",
    "        elif y[i] == 0 and y_pred[i] == 1:\n",
    "            fp += 1\n",
    "    accuracy = (tp + tn)/(tp+fp+tn+fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1 = round((beta**2+1)*precision*recall/(beta**2*precision+recall),4)\n",
    "    conf_matrix = pd.DataFrame(([tp,fp],[fn,tn]),['y_pred +', 'y_pred -'], columns=['y+', 'y-'])\n",
    "\n",
    "    return accuracy, precision, recall, f1, conf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, pre, rec, f1, mat = metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9    Precision: 1.0    Recall: 0.8    F1_score: 0.8889\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {acc}    Precision: {pre}    Recall: {rec}    F1_score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y+</th>\n",
       "      <th>y-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y_pred +</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_pred -</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          y+  y-\n",
       "y_pred +   4   0\n",
       "y_pred -   1   5"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion matrix:')\n",
    "mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Могла ли модель переобучиться? Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Данные неплохо разделимы + их мало => модель старается изо всех сил быть крутой и точной и предсказывать вероятности близкие к 0 и 1 => переобучается и становится квадратной. Если бы данные накладывались друг на друга немного, модель бы не переобучилась, т.к. она линейная по сути**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lesson_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
